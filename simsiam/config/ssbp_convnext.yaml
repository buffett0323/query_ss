# W&B settings
log_wandb: True #False
wandb_project_name: "SimSiam Training"
wandb_name: "ConvNeXt-Base + 4 Augs"
wandb_notes: "ConvNeXt-Base,Fatcat, Amp_Seg-0.95sec, Augmentation: Seq Perturb + Reverse 0.8 -> Time mask -> Pitch shift -> Time stretch, lr:5e-2"


# Directory settings
data_dir: "/mnt/gestalt/home/ddmanddman/beatport_analyze/chorus_audio_16000_4secs_npy"
seg_dir: "/mnt/gestalt/home/buffett/beatport_analyze/chorus_audio_16000_095sec_npy_bass_other_new/amp_08"
# data_dir: "/home/buffett/dataset/beatport_analyze/chorus_audio_16000_npy"
model_dict_save_path: "/mnt/gestalt/home/buffett/simsiam_model_dict/convnext_model_dict_0423"
model_lincls_save_path: "/mnt/gestalt/home/buffett/simsiam_model_dict/convnext_lincls_model_dict_0423"
# model_dict_save_dir: "/home/buffett/dataset/resnet_50_model_dict"
workers: 24 # 24 for terra, 56 for fatcat


# LMDB settings
lmdb_dir: "/mnt/gestalt/home/buffett/beatport_analyze/lmdb"
use_lmdb: True

# train options
seed: 42 # sacred handles automatic seeding when passed in the config
batch_size: 256 #256 
start_epoch: 0
epochs: 500 # 200
lr: 0.05 # 0.05 #0.001
momentum: 0.9
warmup_epochs: 20 # 10
dim: 1024 # 2048 # TODO: Try different dimensions
pred_dim: 512
resume: '' # path to latest checkpoint (default: none)
fix_pred_lr: True
print_freq: 20
encoder_name: "ConvNeXt"
sp_method: "fixed" # "random", "fixed", "adaptive", "reverse"
norm_stats: [-5.36902,  3.7100384]
lars: True


# dataset options
train_mode: "augmentation" # "aug+sel"
segment_second: 0.95
piece_second: 4
max_length: 64
n_fft: 1024 #2048
hop_length: 160 #320 #512 #1024
sample_rate: 16000 #44100 Temporarily transform to 16000
window_size: 1024 #512
n_mels: 64 #128
fmin: 20 #20
fmax: 8000 #8000 # 16000/2
pin_memory: True
drop_last: True #False
persistent_workers: True
SEGMENT_TIME: 0.95
SAMPLE_RATE: 16000
AMP_THRES: 0.5
fixed_second: 0.3
num_seq_segments: 5
p_ts: 0.8 # 0.5 # Sequence Perturbation
p_ps: 0.5 # 0.4 # Pitch Shift
p_tm: 0.5 # 0.5 # Time Mask
p_tstr: 0.5 # 0.5 # Time Stretch
tm_min_band_part: 0.05 #0.1
tm_max_band_part: 0.1 #0.15
tm_fade: True
p_mask: 0.5 # 0.5 # Time Mask
semitone_range: [-2, 2] # [-4, 4]
tstr_min_rate: 0.8
tstr_max_rate: 1.25


# model options
channels: 1
convnext_model: "base" # "tiny", "small", "base", "large"

# loss options
optimizer: "Adam" # or LARS (experimental)
weight_decay: 1.0e-4 #1.0e-4 #1.0e-6 # "optimized using LARS [...] and weight decay of 10âˆ’6"
temperature: 0.1 #0.5 # see appendix B.7.: Optimal temperature under different batch sizes
lr_decay_factor: 0.05 #0.01


# reload options
model_path: "save" # set to the directory containing `checkpoint_##.tar` 
reload: False

# knn options
knn_k: 3 #200
knn_t: 1.0 #0.2
